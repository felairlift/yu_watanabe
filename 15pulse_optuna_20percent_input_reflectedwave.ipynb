{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import DataParallel\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetTemperature, nvmlShutdown, NVML_TEMPERATURE_GPU\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pynvml\n",
    "import optuna\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42\n",
    "start_time=time.time()\n",
    "\n",
    "def timecount():\n",
    "    end_time=time.time()\n",
    "    elapsed_time=end_time-start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)  # 3600秒 = 1時間\n",
    "    minutes, seconds = divmod(rem, 60)  # 60秒 = 1分\n",
    "    # 経過時間の表示\n",
    "    print(f\"処理にかかった時間: {int(hours)}時間 {int(minutes)}分 {seconds:.2f}秒\")\n",
    "def memoricount():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()  # ガベージコレクタを明示的に呼び出す\n",
    "    # NVMLの初期化\n",
    "    pynvml.nvmlInit()\n",
    "    # 各GPUのメモリ情報を取得して表示\n",
    "    for i in range(3):\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        total_memory = memory_info.total / 1024**3  # GB単位\n",
    "        used_memory = memory_info.used / 1024**3    # GB単位\n",
    "        free_memory = memory_info.free / 1024**3    # GB単位\n",
    "        #print(f\"GPU {i}:\")\n",
    "        #print(f\"  Total Memory: {total_memory:.2f} GB\")\n",
    "        print(f\" GPU {i}: Used Memory: {used_memory:.2f} GB\")\n",
    "        #print(f\"  Free Memory: {free_memory:.2f} GB\")\n",
    "    # NVMLの終了\n",
    "    pynvml.nvmlShutdown()\n",
    "    \n",
    "def wait_for_gpu_temperature(threshold=65, check_interval=7*60):\n",
    "    \"\"\"\n",
    "    GPUの温度が指定の閾値以下になるまで待機する関数。\n",
    "    Args:\n",
    "        threshold (int): 温度の閾値（℃）。\n",
    "        check_interval (int): 温度チェックの間隔（秒）。\n",
    "\n",
    "    \"\"\"\n",
    "    # NVMLの初期化\n",
    "    for gpu_index in range(0):\n",
    "        nvmlInit()\n",
    "        try:\n",
    "            handle = nvmlDeviceGetHandleByIndex(gpu_index)\n",
    "            while True:\n",
    "                # 現在のGPU温度を取得\n",
    "                temperature = nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)\n",
    "                print(f\"GPU {gpu_index} 温度: {temperature}℃\")\n",
    "                \n",
    "                if temperature <= threshold:\n",
    "                    #print(f\"GPU {gpu_index} の温度が {threshold}℃ 以下になりました。処理を再開します。\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"GPU {gpu_index} の温度が {threshold}℃ を超えています。{check_interval} 秒後に再チェックします。\")\n",
    "                    time.sleep(check_interval)\n",
    "        finally:\n",
    "            # NVMLの終了処理\n",
    "            nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, shape, epsilon=np.float32(1e-5)):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.tensor(np.ones(shape, dtype='float32')))\n",
    "        self.beta = nn.Parameter(torch.tensor(np.zeros(shape, dtype='float32')))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, (0, 2, 3), keepdim=True)  # WRITE ME\n",
    "        std = torch.std(x, (0, 2, 3), keepdim=True)  # WRITE ME\n",
    "        x_normalized = (x - mean) / (std**2 + self.epsilon)**0.5  # WRITE ME\n",
    "        return self.gamma * x_normalized + self.beta  # WRITE ME\n",
    "    \n",
    "class Dropout(nn.Module):\n",
    "    \"\"\"\n",
    "    http://arxiv.org/abs/1207.0580\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 学習時はdropout_ratio分だけ出力をシャットアウト\n",
    "        if self.training:\n",
    "            self.mask = torch.rand(*x.size()) > self.dropout_ratio\n",
    "            return x * self.mask.to(x.device)\n",
    "        # 推論時は出力に`1.0 - self.dropout_ratio`を乗算することで学習時の出力の大きさに合わせる\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "        \n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, filter_shape, function=lambda x: x, stride=(1, 1), padding=0):\n",
    "        super().__init__()\n",
    "        # Heの初期化\n",
    "        # filter_shape: (出力チャンネル数)x(入力チャンネル数)x(縦の次元数)x(横の次元数)\n",
    "        fan_in = filter_shape[1] * filter_shape[2] * filter_shape[3]\n",
    "        fan_out = filter_shape[0] * filter_shape[2] * filter_shape[3]\n",
    "\n",
    "        self.W = nn.Parameter(torch.tensor(rng.normal(\n",
    "                        0,\n",
    "                        np.sqrt(2/fan_in),\n",
    "                        size=filter_shape\n",
    "                    ).astype('float32')))\n",
    "\n",
    "        # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n",
    "        self.b = nn.Parameter(torch.tensor(np.zeros((filter_shape[0]), dtype='float32')))\n",
    "\n",
    "        self.function = function  # 活性化関数\n",
    "        self.stride = stride  # ストライド幅\n",
    "        self.padding = padding  # パディング\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = F.conv2d(x, self.W, bias=self.b, stride=self.stride, padding=self.padding)\n",
    "        return self.function(u)\n",
    "    \n",
    "class Pooling(nn.Module):\n",
    "    def __init__(self, ksize=(1, 1), stride=(1, 1), padding=0):\n",
    "        super().__init__()\n",
    "        self.ksize = ksize  # カーネルサイズ\n",
    "        self.stride = stride  # ストライド幅\n",
    "        self.padding = padding  # パディング\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.max_pool2d(x, kernel_size=self.ksize, stride=self.stride, padding=self.padding)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)\n",
    "    \n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        super().__init__()\n",
    "        # Heの初期化\n",
    "        # in_dim: 入力の次元数，out_dim: 出力の次元数       \n",
    "        self.W = nn.Parameter(torch.tensor(rng.normal(\n",
    "                        0,\n",
    "                        np.sqrt(2/in_dim),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32')))\n",
    "        \n",
    "        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n",
    "        self.function = function\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.function(torch.matmul(x, self.W) + self.b)\n",
    "    \n",
    "class Activation(nn.Module):\n",
    "\n",
    "    def __init__(self, function=lambda x: x):\n",
    "        super().__init__()\n",
    "        self.function = function\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.function(x)\n",
    "\n",
    "def torch_log(x):\n",
    "    return torch.log(torch.clamp(x, min=1e-10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in dataloader_train: 390\n",
      "Number of samples in dataset_train: 12456\n",
      "  Used Memory: 0.24 GB\n"
     ]
    }
   ],
   "source": [
    "#prese_1pulse_dataloader_save.pyにて作成したデータを読み込む。\n",
    "# 保存したテンソルを読み込み\n",
    "X_train, y_train = torch.load('/mnt/sdb/ywatanabe/CNN_dataset/reflectedwave_rawcsv/15pulse/dataset_train_1129.pt')\n",
    "X_valid, y_valid = torch.load('/mnt/sdb/ywatanabe/CNN_dataset/reflectedwave_rawcsv/15pulse/dataset_valid_1129.pt')\n",
    "\n",
    "\n",
    "# PyTorchのテンソルをNumPy配列に変換\n",
    "X_train_np, y_train_np = X_train.numpy(), y_train.numpy()\n",
    "X_valid_np, y_valid_np = X_valid.numpy(), y_valid.numpy()\n",
    "\n",
    "# train_test_splitでデータを分割\n",
    "X_train_np, X_no_use_np, y_train_np, y_no_use_np = train_test_split(X_train_np, y_train_np, test_size=0.8, random_state=22)\n",
    "X_valid_np, X_no_use_np, y_valid_np, y_no_use_np = train_test_split(X_valid_np, y_valid_np, test_size=0.8, random_state=22)\n",
    "\n",
    "# NumPy配列を再びPyTorchテンソルに戻す\n",
    "X_train, y_train = torch.tensor(X_train_np), torch.tensor(y_train_np)\n",
    "X_valid, y_valid = torch.tensor(X_valid_np), torch.tensor(y_valid_np)\n",
    "\n",
    "\n",
    "# TensorDataset と DataLoader を再作成\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_valid = TensorDataset(X_valid, y_valid)\n",
    "batch_size = 64\n",
    "\n",
    "loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(dataset=dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "# DataLoaderのサイズ（バッチ数）\n",
    "num_batches = len(loader_train)\n",
    "print(f'Number of batches in dataloader_train: {num_batches}')\n",
    "\n",
    "# データセット全体のサイズ（サンプル数）\n",
    "dataset_size = len(dataset_train)\n",
    "print(f'Number of samples in dataset_train: {dataset_size}')\n",
    "del X_train,X_valid,y_train,y_valid,dataset_train,dataset_valid,X_train_np, X_no_use_np, y_train_np, y_no_use_np,X_valid_np, y_valid_np,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(trial, model):\n",
    "  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n",
    "  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "  if optimizer_name == optimizer_names[0]: \n",
    "    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "  elif optimizer_name == optimizer_names[1]:\n",
    "    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n",
    "  else:\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "  return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "                \n",
    "        device = torch.device(\"cuda:0\")  # メインのGPUを指定    optimizer = optim.SGD(conv_net.parameters(), lr=lr)\n",
    "        avg_train_mse=0.0\n",
    "        avg_valid_mse=0.0              \n",
    "        avg_train_mse_list=[]\n",
    "        avg_valid_mse_list=[]\n",
    "\n",
    "        # 相関係数の計算\n",
    "        correlation_coefficient_list=[]\n",
    "        mae_list = []\n",
    "        relative_error_list = []    \n",
    "        try:\n",
    "\n",
    "                #畳み込み層の数\n",
    "                filter_number = trial.suggest_int(\"filter_number\", 64, 128)\n",
    "                y_length = 15\n",
    "                x_length = 4011\n",
    "                x_conv = int(trial.suggest_int(\"x_conv\", 2, 60))\n",
    "                x_stride = int(trial.suggest_int(\"x_stride\", 1, 2))\n",
    "                conv_padding = 0\n",
    "                y_conv=2\n",
    "                y_stride=1\n",
    "                y_pool=1\n",
    "                x_pool = int(trial.suggest_int(\"x_pool\", 4, 8))\n",
    "                lr = trial.suggest_float('learning rate', 0.0001, 0.002, log=True)\n",
    "                n_epochs = 20\n",
    "                Dense2_length = int(trial.suggest_int(\"mid_units\", 64, 128))\n",
    "            \n",
    "                \n",
    "                \n",
    "                path_in='/mnt/sdb/ywatanabe/Saved_png_after1130/reflectedwave_rawcsv/20percent_input/15pulse'\n",
    "                \n",
    "                path_in=os.path.join(path_in,\"y_conv=\"+str(y_conv))\n",
    "                print(f\"Training with parameters: x_length={x_length}, x_conv={x_conv}, x_stride={x_stride}, x_pool={x_pool}, \"\n",
    "                        f\"filter_number={filter_number}, lr={lr}, n_epochs={n_epochs}\")\n",
    "                Title=\"x_conv\"+str(x_conv)+\"x_stride\"+str(x_stride)+\"x_pool\"+str(x_pool)+\"Filter_number\"+str(filter_number)+\"lr\"+str(lr)+\"batchsize\"+str(batch_size)\n",
    "                path_image=os.path.join(\"/mnt/sdb/ywatanabe/Saved_png_after1130/reflectedwave_rawcsv/20percent_input/15pulse/mse\",Title+\".png\")\n",
    "                \n",
    "                B1_x_length=int((x_length+2*conv_padding-x_conv)//x_stride+1)\n",
    "                B2_x_length=int((B1_x_length//x_pool+2*conv_padding-x_conv)//x_stride+1)\n",
    "                B1_y_length=int((y_length+2*conv_padding-y_conv)//y_stride+1)\n",
    "                B2_y_length=int((B1_y_length//y_pool+2*conv_padding-y_conv)//y_stride+1)   \n",
    "                Dense_length=int((B2_x_length//x_pool)*(B2_y_length//y_pool)*filter_number)\n",
    "                conv_net = nn.Sequential(\n",
    "                Conv(filter_shape=(filter_number, 1, y_conv, x_conv), stride=(1, x_stride), padding=conv_padding),        # 画像の大きさ：1x4012x1 -> 1x3996x64  # WRITE ME(入出力の画像サイズ）\n",
    "                BatchNorm((filter_number, B1_y_length, B1_x_length)),    #15pulse分あるため\n",
    "                Activation(F.relu),\n",
    "                Pooling(ksize=(1, x_pool), stride=(1, x_pool), padding=conv_padding),            # 1x3996x64 -> 1x999x64  # WRITE ME(入出力の画像サイズ）\n",
    "                Conv(filter_shape=(filter_number, filter_number, y_conv, x_conv),stride=(1, x_stride)),       # 1x999x64 -> 1x983x64  # WRITE ME(入出力の画像サイズ）\n",
    "                BatchNorm((filter_number, B2_y_length, B2_x_length)),\n",
    "                Activation(F.relu),\n",
    "                Pooling(ksize=(1, x_pool), stride=(1, x_pool)),            # 1x983x64 -> 1x250x64????なぜかこうなってる  # WRITE ME(入出力の画像サイズ）\n",
    "                Flatten(),\n",
    "                Dense(Dense_length, Dense2_length, F.relu),  # 1\n",
    "                Dense(Dense2_length, 1)\n",
    "                )\n",
    "                \n",
    "                conv_net = conv_net.to(device)  # モデルを指定したGPUに移動\n",
    "                #conv_net = DataParallel(conv_net, device_ids=[ 1, 0, 2], output_device=1)  # GPU1を主デバイスに設定\n",
    "                criterion = nn.MSELoss()\n",
    "                #optimizer = get_optimizer(trial, conv_net)\n",
    "                optimizer = optim.SGD(conv_net.parameters(), lr=lr)\n",
    "\n",
    "                \n",
    "                for epoch in range(n_epochs):\n",
    "                        #train\n",
    "                        #memoricount()    \n",
    "                        conv_net.train()  # 訓練モードにする]\n",
    "                        total_trainloss = 0.0\n",
    "                        for x, t in loader_train:\n",
    "                                conv_net.zero_grad()  # 勾配の初期化\n",
    "                                x = x.to(device).float()  # テンソルをGPUに移動し、データ型をfloat32に変換\n",
    "                                t = t.to(device).float()\n",
    "                                y = conv_net.forward(x)  # 順伝播\n",
    "                                y = y.squeeze(dim=1)\n",
    "                                loss = criterion(y, t)\n",
    "                                loss.backward()  # 誤差の逆伝播\n",
    "                                optimizer.step()  # パラメータの更新\n",
    "                                total_trainloss += loss.item()\n",
    "                        avg_train_mse = total_trainloss / len(loader_train)\n",
    "                        avg_train_mse_list.append(avg_train_mse)\n",
    "\n",
    "                        #test\n",
    "                        y_list = []\n",
    "                        t_list = []\n",
    "                        total_validloss = 0.0\n",
    "\n",
    "                        conv_net.eval()\n",
    "                        with torch.no_grad():\n",
    "                                for x, t in loader_valid:\n",
    "                                        x = x.to(device)  # テンソルをGPUに移動\n",
    "\n",
    "                                        t = t.to(device)\n",
    "                                        y = conv_net.forward(x)  # 順伝播\n",
    "                                        y = y.squeeze(dim=1)\n",
    "\n",
    "                                        loss = criterion(y, t)\n",
    "                                        y_list.extend(y)\n",
    "                                        t_list.extend(t)\n",
    "                                                \n",
    "                                        # バッチごとの損失を蓄積\n",
    "                                        total_validloss += loss.item()\n",
    "                        avg_valid_mse = total_validloss / len(loader_valid)\n",
    "                        avg_valid_mse_list.append(avg_valid_mse)\n",
    "                        if np.isnan(avg_train_mse):\n",
    "                                print(\"Loss became NaN. Stopping training.\")\n",
    "                                \n",
    "                                break\n",
    "                        if np.isnan(avg_valid_mse):\n",
    "                                print(\"Loss became NaN. Stopping training.\")\n",
    "                                break\n",
    "                        if epoch%5==4:\n",
    "                                timecount()\n",
    "                                print('EPOCH: {}, Train [Loss: {:.6f} ], Valid [Loss: {:.6f} ]'.format(\n",
    "                                        epoch,\n",
    "                                        avg_train_mse,\n",
    "                                        avg_valid_mse\n",
    "                                        ))\n",
    "\n",
    "                        # y_list と t_list をそれぞれ numpy 配列に変換\n",
    "                        y_array = np.array([y.cpu().numpy() for y in y_list])\n",
    "                        t_array = np.array([t.cpu().numpy() for t in t_list])\n",
    "\n",
    "                        # グラフを描画\n",
    "                        plt.figure(figsize=(10, 10))\n",
    "                        plt.scatter(t_array, y_array, alpha=0.08)  # 散布図として描画\n",
    "                        #plt.plot(t_array, y_array, linestyle='-', alpha=0.2)  # 折れ線としても表示することで変化を見やすく\n",
    "                        plt.plot([0, 0.2], [0, 0.2], color='red', linestyle='--', label='y = x')  # 基準線\n",
    "                        plt.xlim(0,0.2)\n",
    "                        plt.ylim(0,0.2)\n",
    "                        plt.xlabel(\"t_list (Ground Truth)\")\n",
    "                        plt.ylabel(\"y_list (Predicted)\")\n",
    "                        Title=\"x_conv\"+str(x_conv)+\"x_stride\"+str(x_stride)+\"x_pool\"+str(x_pool)+\"Filter_number\"+str(filter_number)+\"epoch\"+str(epoch)+\"lr\"+str(lr)\n",
    "                        plt.title(Title)\n",
    "                        plt.grid(True)\n",
    "                        path_image=os.path.join(path_in,\"plot\",Title+\".png\")\n",
    "                        plt.savefig(path_image, format=\"png\", dpi=300)\n",
    "                        #plt.show()\n",
    "                        plt.close()\n",
    "                        # グラフを描画\n",
    "\n",
    "                        plt.figure(figsize=(12, 10))\n",
    "                                # ヒストグラムを2Dカラーマップで描画\n",
    "                        plt.hist2d(t_array.flatten(), y_array.flatten(), bins=40, range=[[0, 0.2], [0, 0.2]], cmap='viridis', cmin=0, density=True)\n",
    "                        plt.colorbar(label=\"Frequency\")  # カラーバーを追加    \n",
    "                        plt.plot([0, 0.2], [0, 0.2], color='red', linestyle='--', label='y = x')  # 基準線\n",
    "                        plt.xlim(0,0.2)\n",
    "                        plt.ylim(0,0.2)\n",
    "                        plt.xlabel(\"t_list (Ground Truth)\")\n",
    "                        plt.ylabel(\"y_list (Predicted)\")\n",
    "                        Title=\"x_conv\"+str(x_conv)+\"x_stride\"+str(x_stride)+\"x_pool\"+str(x_pool)+\"Filter_number\"+str(filter_number)+\"epoch\"+str(epoch)+\"lr\"+str(lr)+\"midlength\"+str(Dense2_length)\n",
    "                        plt.title(Title)\n",
    "                        plt.grid(True)\n",
    "                        path_image=os.path.join(path_in,\"colormap\",Title+\".png\")\n",
    "                        plt.savefig(path_image, format=\"png\", dpi=300)\n",
    "                        #plt.show()\n",
    "                        plt.close()\n",
    "\n",
    "                        correlation_coefficient = np.corrcoef(y_array.flatten(), t_array.flatten())[0, 1]# 相関係数の計算\n",
    "                        mae = np.mean(np.abs(y_array - t_array))# MAE (Mean Absolute Error) の計算\n",
    "                        relative_error = np.mean(np.abs(y_array - t_array) / (np.abs(t_array) + 1e-8))  # 相対誤差 (Relative Error) の計算# 真の値が0の場合はゼロ除算を防ぐために条件を追加\n",
    "                        correlation_coefficient_list.append(correlation_coefficient)\n",
    "                        mae_list.append(mae)\n",
    "                        relative_error_list.append(relative_error)\n",
    "                if not np.isnan(avg_valid_mse):\n",
    "\n",
    "                        plt.figure(figsize=(10, 10))\n",
    "                        plt.plot(range(1,n_epochs), avg_train_mse_list[1:])\n",
    "                        plt.plot(range(1,n_epochs), avg_valid_mse_list[1:], c='#00ff00')\n",
    "                        #print(avg_valid_mse_list)\n",
    "                        #plt.xlim(0, n_epochs)\n",
    "                        #plt.ylim(0, 2.5)\n",
    "                        plt.xticks(np.arange(0, 20, 5))\n",
    "\n",
    "                        plt.xlabel('EPOCH')\n",
    "                        plt.ylabel('LOSS')\n",
    "                        plt.legend(['train loss', 'test loss'])\n",
    "                        Title=\"x_conv\"+str(x_conv)+\"x_stride\"+str(x_stride)+\"x_pool\"+str(x_pool)+\"Filter_number\"+str(filter_number)+\"lr\"+str(lr)+\"batchsize\"+str(batch_size)+\"mid_length\"+str(Dense2_length)\n",
    "                        plt.title(Title)\n",
    "                        path_image=os.path.join(path_in,\"mse\",Title+\".png\")\n",
    "                        plt.savefig(path_image, format=\"png\", dpi=300)\n",
    "                        plt.close()\n",
    "\n",
    "                        # 保存するデータ\n",
    "                        data = [\n",
    "                                {\"epoch\": epoch + 1,\n",
    "                                \"correlation_coefficient\": correlation_coefficient_list[epoch],\n",
    "                                \"mae\": mae_list[epoch],\n",
    "                                \"train_mse\": avg_train_mse_list[epoch],\n",
    "                                \"valid_mse\": avg_valid_mse_list[epoch],\n",
    "                                \"relative_error\": relative_error_list[epoch]}\n",
    "                                for epoch in range(n_epochs)\n",
    "                        ]\n",
    "                        # 保存するCSVファイル名\n",
    "                        path_csv=os.path.join(path_in,\"csv\",Title+\".csv\")\n",
    "                        # CSVファイルに書き込み\n",
    "                        with open(path_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                                # ヘッダーを作成\n",
    "                                fieldnames = [\"epoch\", \"correlation_coefficient\", \"mae\", \"train_mse\",\"valid_mse\",\"relative_error\"]\n",
    "                                writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                                # ヘッダーを書き込み\n",
    "                                writer.writeheader()\n",
    "                                # データを書き込み\n",
    "                                writer.writerows(data)\n",
    "\n",
    "                        #wait_for_gpu_temperature(threshold=65,  check_interval=3*60)\n",
    "                        print(datetime.datetime.now())\n",
    "                        time.sleep(1*60)\n",
    "        except RuntimeWarning as e:\n",
    "                print(f\"RuntimeWarning: {e}\")\n",
    "                avg_valid_mse = np.nan\n",
    "        except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                avg_valid_mse = np.nan\n",
    "\n",
    "\n",
    "        return avg_valid_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: x_length=4011, x_conv=9, x_stride=2, x_pool=8, filter_number=90, lr=0.000699964676350053, n_epochs=20\n",
      "処理にかかった時間: 0時間 3分 43.91秒\n",
      "EPOCH: 4, Train [Loss: 0.001906 ], Valid [Loss: 0.001814 ]\n",
      "処理にかかった時間: 0時間 6分 55.74秒\n",
      "EPOCH: 9, Train [Loss: 0.001517 ], Valid [Loss: 0.001490 ]\n",
      "処理にかかった時間: 0時間 10分 7.72秒\n",
      "EPOCH: 14, Train [Loss: 0.001364 ], Valid [Loss: 0.001338 ]\n",
      "処理にかかった時間: 0時間 13分 19.53秒\n",
      "EPOCH: 19, Train [Loss: 0.001256 ], Valid [Loss: 0.001256 ]\n",
      "2024-11-30 20:26:33.782106\n",
      "Training with parameters: x_length=4011, x_conv=47, x_stride=2, x_pool=6, filter_number=76, lr=0.00013554746996554843, n_epochs=20\n",
      "処理にかかった時間: 0時間 18分 37.15秒\n",
      "EPOCH: 4, Train [Loss: 0.004496 ], Valid [Loss: 0.001828 ]\n",
      "処理にかかった時間: 0時間 23分 0.65秒\n",
      "EPOCH: 9, Train [Loss: 0.002691 ], Valid [Loss: 0.001602 ]\n",
      "処理にかかった時間: 0時間 27分 23.01秒\n",
      "EPOCH: 14, Train [Loss: 0.002189 ], Valid [Loss: 0.001477 ]\n",
      "処理にかかった時間: 0時間 31分 39.97秒\n",
      "EPOCH: 19, Train [Loss: 0.001985 ], Valid [Loss: 0.001397 ]\n",
      "2024-11-30 20:44:54.117772\n",
      "Training with parameters: x_length=4011, x_conv=58, x_stride=1, x_pool=5, filter_number=121, lr=0.00024466144029722475, n_epochs=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 2 failed with parameters: {'filter_number': 121, 'x_conv': 58, 'x_stride': 1, 'x_pool': 5, 'learning rate': 0.00024466144029722475, 'mid_units': 91} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_89771/3191725669.py\", line 82, in objective\n",
      "    total_trainloss += loss.item()\n",
      "KeyboardInterrupt\n",
      "Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m TRIAL_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      6\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(storage\u001b[38;5;241m=\u001b[39mstorage_name, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20percent_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIAL_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# optuna-dashboard sqlite:////mnt/sdb/ywatanabe/CNN_dataset/transwave/optuna_data/20percent_input_after1130.db --port 8081\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 上記分をターミナルで実行すればよい\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[5], line 82\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     80\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 誤差の逆伝播\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# パラメータの更新\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m         total_trainloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m avg_train_mse \u001b[38;5;241m=\u001b[39m total_trainloss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader_train)\n\u001b[1;32m     84\u001b[0m avg_train_mse_list\u001b[38;5;241m.\u001b[39mappend(avg_train_mse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "db_path = \"/mnt/sdb/ywatanabe/CNN_dataset/reflectedwave_rawcsv/optuna_data/20percent_input_after1130_nodropout.db\"\n",
    "storage_name = f\"sqlite:///{db_path}\"\n",
    "\n",
    "\n",
    "TRIAL_SIZE = 100\n",
    "study = optuna.create_study(storage=storage_name, study_name=\"20percent_input\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=TRIAL_SIZE)\n",
    "# optuna-dashboard sqlite:////mnt/sdb/ywatanabe/CNN_dataset/transwave_rawcsv/optuna_data/20percent_input_transwave.db --port 8070\n",
    "# 上記分をターミナルで実行すればよい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Record does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_value\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest param: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/study.py:133\u001b[0m, in \u001b[0;36mStudy.best_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_value\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the best objective value in the study.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     best_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m best_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_value\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/study/study.py:162\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m constraints \u001b[38;5;241m=\u001b[39m best_trial\u001b[38;5;241m.\u001b[39msystem_attrs\u001b[38;5;241m.\u001b[39mget(_CONSTRAINTS_KEY)\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/storages/_cached_storage.py:182\u001b[0m, in \u001b[0;36m_CachedStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_id: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrozenTrial:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/storages/_rdb/storage.py:936\u001b[0m, in \u001b[0;36mRDBStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    934\u001b[0m         trial_id \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mTrialModel\u001b[38;5;241m.\u001b[39mfind_max_value_trial_id(study_id, \u001b[38;5;241m0\u001b[39m, session)\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m         trial_id \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrialModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_min_value_trial_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_trial(trial_id)\n",
      "File \u001b[0;32m/mnt/sdb/ywatanabe/yuwatanabe/yuvenv/lib/python3.10/site-packages/optuna/storages/_rdb/models.py:236\u001b[0m, in \u001b[0;36mTrialModel.find_min_value_trial_id\u001b[0;34m(cls, study_id, objective, session)\u001b[0m\n\u001b[1;32m    216\u001b[0m trial \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    217\u001b[0m     session\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;241m.\u001b[39mwith_entities(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;241m.\u001b[39mone_or_none()\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(NOT_FOUND_MSG)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Record does not exist."
     ]
    }
   ],
   "source": [
    "print(f'Best value: {study.best_value}')\n",
    "print(f'Best param: {study.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "#db_path = \"/mnt/sdb/ywatanabe/CNN_dataset/optuna_data/example.db\"\n",
    "if False:\n",
    "\n",
    "    # データベースに接続\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # データベース内のテーブルを確認\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    print(cursor.fetchall())\n",
    "\n",
    "    # 特定のテーブル内容を確認（例: `trials` テーブル）\n",
    "    cursor.execute(\"SELECT * FROM trials;\")\n",
    "    print(cursor.fetchall())\n",
    "\n",
    "    # 接続を閉じる\n",
    "    conn.close()\n",
    "# optuna-dashboard sqlite:////mnt/sdb/ywatanabe/CNN_dataset_for_presen/15pulse_20percent_transwave_1124.db --port 2000\n",
    "# 上記分をターミナルで実行すればよい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
